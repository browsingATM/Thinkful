{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to revisit your classifier from the previous assignment. Using the evaluation techniques we've covered here, look at your classifier's performance in more detail. Then go back and iterate by engineering new features, removing poor features, or tuning parameters. Repeat this process until you have five different versions of your classifier. Once you've iterated, answer these questions to compare the performance of each:\n",
    "\n",
    "    1. Do any of your classifiers seem to overfit?\n",
    "    2. Which seem to perform the best? Why?\n",
    "    3. Which features seemed to be most impactful to performance?\n",
    "\n",
    "Write up your iterations and answers to the above questions in a few pages. Submit a link below and go over it with your mentor to see if they have any other ideas on how you could improve your classifier's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab and process the RAW data.\n",
    "data_path = (\"https://raw.githubusercontent.com/browsingATM/Thinkful/master/Unit%202/yelp_labelled.txt\")\n",
    "            \n",
    "yelp_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "yelp_raw.columns = ['review', 'score']\n",
    "#score of 1 = positive, score of 0 = negative\n",
    "\n",
    "\n",
    "yelp_keywords = ['love', 'loved', 'mmm', 'so good', 'so great', 'perfect', 'amazing', 'above and beyond', \n",
    "           'great customer service', 'so yummy', 'sexy', 'really good', 'great ambience', 'pleasant',\n",
    "           'check it out', 'worth the time', 'worth the money', 'hit the spot', 'was full', 'tummy', 'phenomenal food']\n",
    "\n",
    "for ykey in yelp_keywords:\n",
    "    yelp_raw[str(ykey)] = yelp_raw.review.str.contains(\n",
    "    ' ' + str(ykey) + ' ',\n",
    "    case=False\n",
    "    )\n",
    "\n",
    "data = yelp_raw[yelp_keywords]\n",
    "target = yelp_raw['score']\n",
    "\n",
    "#binary data so using BNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#instantiate our model and store it in a new variable\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "#fit data to our model\n",
    "bnb.fit(data, target)\n",
    "\n",
    "#classify, storing the result in a new variable\n",
    "y_pred = bnb.predict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "holdout groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.555\n",
      "Testing on Sample: 0.541\n"
     ]
    }
   ],
   "source": [
    "# Test your model with different holdout groups.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.534,  0.54 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do any of your classifiers seem to overfit?\n",
    "-> Both do. \n",
    "2. Which seem to perform the best? Why?\n",
    "-> cross validation since \n",
    "3. Which features seemed to be most impactful to performance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
