{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jakegrosek/miniconda3/envs/minimal_ds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jakegrosek/miniconda3/envs/minimal_ds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jakegrosek/miniconda3/envs/minimal_ds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jakegrosek/miniconda3/envs/minimal_ds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jakegrosek/miniconda3/envs/minimal_ds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jakegrosek/miniconda3/envs/minimal_ds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import classification_report\n",
    "from utils import wav2mfcc, model, get_data\n",
    "import utils\n",
    "import keras\n",
    "import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# wav2mfcc.py\n",
    "\n",
    "def wav2mfcc(file_path, max_pad_len=20):\n",
    "    \"\"\"uses librosa to identify the file, the path, set the sample rate (sr),\n",
    "    and create the proper shape????\"\"\"\n",
    "    # Load an audio file as a floating point time series.\n",
    "    # To preserve the native sampling rate of the file, use sr=None.\n",
    "    # mono=True converts the audio signal to mono.\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    # wave = ??\n",
    "    wave = wave[::3]\n",
    "    # Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=8000)\n",
    "    # set the dimension of the padded array\n",
    "    pad_width = max_pad_len - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)),\n",
    "                  mode='constant') # pads a 'constant' value\n",
    "    return mfcc\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"create a function that loops through the list of audio file names,\n",
    "    adds '.wav' to them, and appends it to a new list, mfccs\"\"\"\n",
    "    labels = []\n",
    "    mfccs = []\n",
    "    \n",
    "    # when searching all the files in this folder\n",
    "    for f in os.listdir('./recordings'):\n",
    "        # if a file ends in .wav\n",
    "        if f.endswith('.wav'):\n",
    "            # MFCC; append the file with its new name in the mfccs folder\n",
    "            mfccs.append(wav2mfcc('./recordings/' + f))\n",
    "\n",
    "            # List of labels\n",
    "            # splits the name of the files?\n",
    "            label = f.split('_')[0]\n",
    "            labels.append(label)\n",
    "    \n",
    "    # convert the returned data to an array\n",
    "    # to_categorical converts a class vector (integers)...\n",
    "    # ...to binary class matrix.\n",
    "    return np.asarray(mfccs), to_categorical(labels)\n",
    "\n",
    "    # MIKE---why optional below? \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     mfccs, labels = get_data()\n",
    "#     print(mfccs.shape)\n",
    "#     print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_all():\n",
    "    \"\"\"create the test train split, create the dimensions, \n",
    "    instantiate X and y, and instantiate the model\"\"\"\n",
    "    \n",
    "    # call Keras utils to read the audio files and convert from\n",
    "    # .wav to mfcc\n",
    "    mfccs, labels = utils.wav2mfcc.get_data()\n",
    "    \n",
    "    # instantiate the dimensions, channels, classes\n",
    "    dim_1 = mfccs.shape[1]\n",
    "    dim_2 = mfccs.shape[2]\n",
    "    channels = 1\n",
    "    classes = 10\n",
    "    \n",
    "    # instantiate X and y\n",
    "    X = mfccs\n",
    "    X = X.reshape((mfccs.shape[0], dim_1, dim_2, channels))\n",
    "    y = labels\n",
    "    \n",
    "    # instantiate the input shape\n",
    "    input_shape = (dim_1, dim_2, channels)\n",
    "    \n",
    "    # set up test-train, test size is 10%; random state established\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=1)\n",
    "    \n",
    "    # instantiate the model\n",
    "    model = utils.model.get_cnn_model(input_shape, classes)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "#model.py\n",
    "\n",
    "\"\"\"creating a model for the convolutional neural network. i can add more....\"\"\"\n",
    "def get_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "    # MIKE---why optional below? \n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     model = get_cnn_model((20, 20, 1), 10)\n",
    "#     #ann_viz(model, title=\"Neural Network Model\", filename='../images/model.gv')\n",
    "#     print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from utils import wav2mfcc, model, get_data\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# test.py\n",
    "def check_preds(X, y):\n",
    "    \"\"\"instantiate the trained model, predictions, and print results\n",
    "    in a classification report from sklearn\"\"\"\n",
    "\n",
    "    # use Keras function load_model\n",
    "    trained_model = keras.models.load_model('trained_model.h5')\n",
    "    # predict_classes is exclusive to Sequential class\n",
    "    predictions = trained_model.predict_classes(X)\n",
    "    \n",
    "    # classification report builds a text report showing the\n",
    "    # main classification metrics; \n",
    "    # to_categorical converts a class vector (integers)\n",
    "    # to a binary class matrix.\n",
    "    print(classification_report(y, to_categorical(predictions)))\n",
    "\n",
    "    # MIKE---why optional below? \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     _, X_test, _, y_test, _ = get_data.get_all()\n",
    "#\n",
    "#     check_preds(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jakegrosek/miniconda3/envs/minimal_ds/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/jakegrosek/.local/lib/python3.7/site-packages/Keras-2.2.5-py3.7.egg/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 19, 19, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 19, 19, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 18, 48)        6192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 18, 18, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 120)       23160     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 17, 120)       480       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 120)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               983168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,023,154\n",
      "Trainable params: 1,022,370\n",
      "Non-trainable params: 784\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /Users/jakegrosek/miniconda3/envs/minimal_ds/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1215 samples, validate on 135 samples\n",
      "Epoch 1/20\n",
      "1215/1215 [==============================] - 7s 6ms/step - loss: 1.9753 - acc: 0.3761 - val_loss: 1.0498 - val_acc: 0.6519\n",
      "Epoch 2/20\n",
      "1215/1215 [==============================] - 5s 5ms/step - loss: 1.0824 - acc: 0.6584 - val_loss: 0.6794 - val_acc: 0.8296\n",
      "Epoch 3/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.8235 - acc: 0.7358 - val_loss: 0.5384 - val_acc: 0.8519\n",
      "Epoch 4/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.6164 - acc: 0.8123 - val_loss: 0.4525 - val_acc: 0.8741\n",
      "Epoch 5/20\n",
      "1215/1215 [==============================] - 6s 5ms/step - loss: 0.5238 - acc: 0.8453 - val_loss: 0.3640 - val_acc: 0.9111\n",
      "Epoch 6/20\n",
      "1215/1215 [==============================] - 6s 5ms/step - loss: 0.4122 - acc: 0.8749 - val_loss: 0.3779 - val_acc: 0.8741\n",
      "Epoch 7/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.3959 - acc: 0.8774 - val_loss: 0.3211 - val_acc: 0.8963\n",
      "Epoch 8/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.3300 - acc: 0.9029 - val_loss: 0.2830 - val_acc: 0.9111\n",
      "Epoch 9/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.2813 - acc: 0.9185 - val_loss: 0.2554 - val_acc: 0.9111\n",
      "Epoch 10/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.2728 - acc: 0.9235 - val_loss: 0.2285 - val_acc: 0.9333\n",
      "Epoch 11/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.2185 - acc: 0.9366 - val_loss: 0.2583 - val_acc: 0.9185\n",
      "Epoch 12/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.2069 - acc: 0.9449 - val_loss: 0.2294 - val_acc: 0.9259\n",
      "Epoch 13/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.1971 - acc: 0.9465 - val_loss: 0.2397 - val_acc: 0.9259\n",
      "Epoch 14/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.1649 - acc: 0.9588 - val_loss: 0.2324 - val_acc: 0.9111\n",
      "Epoch 15/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.1705 - acc: 0.9547 - val_loss: 0.2077 - val_acc: 0.9333\n",
      "Epoch 16/20\n",
      "1215/1215 [==============================] - 5s 4ms/step - loss: 0.1665 - acc: 0.9481 - val_loss: 0.2022 - val_acc: 0.9259\n",
      "Epoch 17/20\n",
      "1215/1215 [==============================] - 6s 5ms/step - loss: 0.1428 - acc: 0.9687 - val_loss: 0.1964 - val_acc: 0.9556\n",
      "Epoch 18/20\n",
      "1215/1215 [==============================] - 6s 5ms/step - loss: 0.1210 - acc: 0.9663 - val_loss: 0.2095 - val_acc: 0.9407\n",
      "Epoch 19/20\n",
      "1215/1215 [==============================] - 6s 5ms/step - loss: 0.1134 - acc: 0.9695 - val_loss: 0.2306 - val_acc: 0.9259\n",
      "Epoch 20/20\n",
      "1215/1215 [==============================] - 6s 5ms/step - loss: 0.1035 - acc: 0.9761 - val_loss: 0.1881 - val_acc: 0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        19\n",
      "           1       0.92      0.80      0.86        15\n",
      "           2       1.00      0.91      0.95        23\n",
      "           3       0.83      1.00      0.91        10\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00        23\n",
      "           6       0.93      1.00      0.96        13\n",
      "           7       1.00      0.92      0.96        13\n",
      "           8       1.00      1.00      1.00        14\n",
      "           9       0.77      1.00      0.87        10\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       150\n",
      "   macro avg       0.95      0.96      0.95       150\n",
      "weighted avg       0.96      0.95      0.95       150\n",
      " samples avg       0.95      0.95      0.95       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import model, wav2mfcc, get_data\n",
    "import test\n",
    "import keras\n",
    "\n",
    "X_train, X_test, y_train, y_test, cnn_model = get_data.get_all()\n",
    "\n",
    "print(cnn_model.summary())\n",
    "\n",
    "# deleted hyperparameter callbacks=[keras_callback] due to errors\n",
    "cnn_model.fit(X_train, y_train, batch_size=64, epochs=20,\n",
    "              verbose=1, validation_split=0.1)\n",
    "\n",
    "cnn_model.save('trained_modelv1.h5')\n",
    "\n",
    "test.check_preds(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MFCCS isn't called?\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mfccs, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codes & articles referenced:\n",
    "- https://github.com/adhishthite/sound-mnist\n",
    "- https://github.com/Jakobovski/free-spoken-digit-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
